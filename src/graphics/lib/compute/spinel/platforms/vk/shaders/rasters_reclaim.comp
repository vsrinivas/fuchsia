// Copyright 2019 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#version 460

//
//
//

#extension GL_GOOGLE_include_directive        : require
#extension GL_KHR_shader_subgroup_basic       : require
#extension GL_KHR_shader_subgroup_ballot      : require

//
//
//

#include "spn_config.h"
#include "spn_vk_layouts.h"

//
//
//

layout(local_size_x = SPN_KERNEL_RASTERS_RECLAIM_WORKGROUP_SIZE) in;

//
// main(buffer uint  bp_atomics[2],
//      buffer uint  bp_ids[],
//      buffer uint  bp_blocks[],
//      buffer uint  map[],
//      uniform uint bp_mask,
//      uniform uint path_ids[])
//

SPN_VK_TARGET_GLSL_DECL_KERNEL_RASTERS_RECLAIM();

//
//
//

#if   (SPN_KERNEL_RASTERS_RECLAIM_EXPAND_SIZE == 1)

#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND()       SPN_EXPAND_1()
#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST  0

#elif (SPN_KERNEL_RASTERS_RECLAIM_EXPAND_SIZE == 2)

#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND()       SPN_EXPAND_2()
#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST  1

#elif (SPN_KERNEL_RASTERS_RECLAIM_EXPAND_SIZE == 4)

#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND()       SPN_EXPAND_4()
#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST  3
#elif (SPN_KERNEL_RASTERS_RECLAIM_EXPAND_SIZE == 8)

#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND()       SPN_EXPAND_8()
#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST  7

#elif (SPN_KERNEL_RASTERS_RECLAIM_EXPAND_SIZE == 16)

#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND()       SPN_EXPAND_16()
#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST  15

#elif (SPN_KERNEL_RASTERS_RECLAIM_EXPAND_SIZE == 32)

#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND()       SPN_EXPAND_32()
#define SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST  31

#endif

//
// CONSTANTS
//

#define SPN_KERNEL_RASTERS_RECLAIM_SUBGROUPS  (SPN_KERNEL_RASTERS_RECLAIM_WORKGROUP_SIZE / SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE)

//
// RUN-TIME PREDICATES
//

#define SPN_RASTERS_RECLAIM_BROADCAST(E,O,I)                            \
  subgroupBroadcast(E,O - I * SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE)

//
//
//

void main()
{
  for (uint reclaim_idx = gl_SubgroupID;
       reclaim_idx < SPN_KERNEL_RASTERS_RECLAIM_MAX_RECLAIM_IDS;
       reclaim_idx += SPN_KERNEL_RASTERS_RECLAIM_SUBGROUPS)
    {
      // get host path id
      const uint raster_h = raster_ids[reclaim_idx];

      // if it's an invalid id then we're done
      if (raster_h == SPN_TAGGED_BLOCK_ID_INVALID)
        return;

      // get the path header block from the map
      uint node_id = bp_host_map[raster_h];

      //
      // load the first half of the head block into registers and
      // start reclaiming blocks
      //
      // the layout of a raster node is:
      //
      //   union {
      //     u32   words[block_size];
      //     struct {
      //       u32 lo[block_size/2];
      //       u32 hi[block_size/2];
      //     };
      //   };
      //
      // FIXME - note that this implies a block has at least (2 *
      // subgroup size) words -- if this isn't the case for a target
      // device we can create a special case
      //

      //
      // load "lo" half of head
      //
      const uint h_idx = node_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS + gl_SubgroupInvocationID;

#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
      uint h##I = bp_blocks[h_idx + I * SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE];

      SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

      //
      // pick out count.blocks and count.nodes from the header
      //
      uint count_blocks, count_nodes;

#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
      if (SPN_RASTER_HEAD_ELEM_IN_RANGE(SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE,SPN_RASTER_HEAD_LO_OFFSET_BLOCKS,I)) { \
        count_blocks = SPN_RASTERS_RECLAIM_BROADCAST(h##I,SPN_RASTER_HEAD_LO_OFFSET_BLOCKS,I); \
      }                                                                 \
      if (SPN_RASTER_HEAD_ELEM_IN_RANGE(SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE,SPN_RASTER_HEAD_LO_OFFSET_NODES,I)) { \
        count_nodes  = SPN_RASTERS_RECLAIM_BROADCAST(h##I,SPN_RASTER_HEAD_LO_OFFSET_NODES,I); \
      }

      SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

      //
      // acquire a span in the block pool ids ring for reclaimed ids
      //
      uint bp_ids_base = 0;

      if (gl_SubgroupInvocationID == 0) {
        bp_ids_base = atomicAdd(bp_atomics[1],count_blocks);
      }

      bp_ids_base = subgroupBroadcastFirst(bp_ids_base);

      //
      // invalidate all header components
      //
#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
      if (!SPN_RASTER_HEAD_ENTIRELY_HEADER(SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE,I)) { \
        if (SPN_RASTER_HEAD_PARTIALLY_HEADER(SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE,I)) { \
          if (SPN_RASTER_HEAD_IS_HEADER(SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE,I)) { \
            h##I = SPN_TAGGED_BLOCK_ID_INVALID;                         \
          }                                                             \
        }                                                               \
      }

      SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

      //
      // shift away all tags
      //
#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
      if (!SPN_RASTER_HEAD_ENTIRELY_HEADER(SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE,I)) { \
        h##I = h##I >> SPN_TAGGED_BLOCK_ID_BITS_TAG;                    \
      }

      SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

      //
      // swap the current node id with the "next" id
      //
      if (gl_SubgroupInvocationID == SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE - 1)
        {
          const uint node_next = SPN_GLSL_CONCAT(h,SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST);

          SPN_GLSL_CONCAT(h,SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST) = node_id;

          node_id = node_next;
        }

      //
      // find ring index of all blocks and store -- FIXME -- NOT COALESCED
      //
#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
      {                                                                 \
        const bool  is_block     = (h##I & SPN_BLOCK_POOL_SUBBLOCKS_PER_BLOCK_MASK) == 0; \
        const uvec4 block_ballot = subgroupBallot(is_block);            \
        const uint  block_idx    = subgroupBallotExclusiveBitCount(block_ballot); \
                                                                        \
        if (is_block)                                                   \
          bp_ids[(bp_ids_base + block_idx) & bp_mask] = h##I;           \
                                                                        \
        bp_ids_base += subgroupBallotBitCount(block_ballot);            \
      }

      SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

      //
      // process next node
      //
      while (count_nodes-- > 0)
        {
          // id of next block is in last lane
          node_id = subgroupBroadcast(node_id,SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE-1);

          //
          // load entire node
          //
          const uint n_idx = node_id * SPN_BLOCK_POOL_SUBBLOCK_DWORDS + gl_SubgroupInvocationID;

#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
          uint n##I = bp_blocks[n_idx + I * SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE];

          SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

          //
          // shift away all tags
          //
#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                           \
          n##I = n##I >> SPN_TAGGED_BLOCK_ID_BITS_TAG;

          SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();

          //
          // swap the current node id with the "next" id
          //
          if (gl_SubgroupInvocationID == SPN_KERNEL_RASTERS_RECLAIM_SUBGROUP_SIZE - 1)
            {
              const uint node_next = SPN_GLSL_CONCAT(n,SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST);

              SPN_GLSL_CONCAT(n,SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND_I_LAST) = node_id;

              node_id = node_next;
            }

          //
          // find ring index of all blocks and store -- FIXME -- NOT COALESCED
          //
#undef  SPN_EXPAND_X
#define SPN_EXPAND_X(I,N,P,L)                                           \
          {                                                             \
            const bool  is_block     = (n##I & SPN_BLOCK_POOL_SUBBLOCKS_PER_BLOCK_MASK) == 0; \
            const uvec4 block_ballot = subgroupBallot(is_block);        \
            const uint  block_idx    = subgroupBallotExclusiveBitCount(block_ballot); \
                                                                        \
            if (is_block)                                               \
              bp_ids[(bp_ids_base + block_idx) & bp_mask] = n##I;       \
                                                                        \
            bp_ids_base += subgroupBallotBitCount(block_ballot);        \
          }

          SPN_KERNEL_RASTERS_RECLAIM_BLOCK_EXPAND();
        }
    }
}

//
//
//
